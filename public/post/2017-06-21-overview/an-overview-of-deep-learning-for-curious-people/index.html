<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>An Overview of Deep Learning for Curious People | Jarvis' Log</title>
<meta name=keywords content="foundation,tutorial"><meta name=description content="I believe many of you have watched or heard of the games between AlphaGo and professional Go player Lee Sedol in 2016. Lee has the highest rank of nine dan and many world championships. No doubt, he is one of the best Go players in the world, but he lost by 1-4 in this series versus AlphaGo. Before this, Go was considered to be an intractable game for computers to master, as its simple rules lay out an exponential number of variations in the board positions, many more than what in Chess. This event surely highlighted 2016 as a big year for AI. Because of AlphaGo, much attention has been attracted to the progress of AI."><meta name=author content="Jarvis Ma"><link rel=canonical href=http://localhost:1313/post/2017-06-21-overview/an-overview-of-deep-learning-for-curious-people/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/post/2017-06-21-overview/an-overview-of-deep-learning-for-curious-people/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script><meta property="og:title" content="An Overview of Deep Learning for Curious People"><meta property="og:description" content="I believe many of you have watched or heard of the games between AlphaGo and professional Go player Lee Sedol in 2016. Lee has the highest rank of nine dan and many world championships. No doubt, he is one of the best Go players in the world, but he lost by 1-4 in this series versus AlphaGo. Before this, Go was considered to be an intractable game for computers to master, as its simple rules lay out an exponential number of variations in the board positions, many more than what in Chess. This event surely highlighted 2016 as a big year for AI. Because of AlphaGo, much attention has been attracted to the progress of AI."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/post/2017-06-21-overview/an-overview-of-deep-learning-for-curious-people/"><meta property="article:section" content="post"><meta property="article:published_time" content="2017-06-21T12:06:59+08:00"><meta property="article:modified_time" content="2017-06-21T12:06:59+08:00"><meta property="og:site_name" content="Jarvis' Log"><meta name=twitter:card content="summary"><meta name=twitter:title content="An Overview of Deep Learning for Curious People"><meta name=twitter:description content="I believe many of you have watched or heard of the games between AlphaGo and professional Go player Lee Sedol in 2016. Lee has the highest rank of nine dan and many world championships. No doubt, he is one of the best Go players in the world, but he lost by 1-4 in this series versus AlphaGo. Before this, Go was considered to be an intractable game for computers to master, as its simple rules lay out an exponential number of variations in the board positions, many more than what in Chess. This event surely highlighted 2016 as a big year for AI. Because of AlphaGo, much attention has been attracted to the progress of AI."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/post/"},{"@type":"ListItem","position":2,"name":"An Overview of Deep Learning for Curious People","item":"http://localhost:1313/post/2017-06-21-overview/an-overview-of-deep-learning-for-curious-people/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"An Overview of Deep Learning for Curious People","name":"An Overview of Deep Learning for Curious People","description":"I believe many of you have watched or heard of the games between AlphaGo and professional Go player Lee Sedol in 2016. Lee has the highest rank of nine dan and many world championships. No doubt, he is one of the best Go players in the world, but he lost by 1-4 in this series versus AlphaGo. Before this, Go was considered to be an intractable game for computers to master, as its simple rules lay out an exponential number of variations in the board positions, many more than what in Chess. This event surely highlighted 2016 as a big year for AI. Because of AlphaGo, much attention has been attracted to the progress of AI.\n","keywords":["foundation","tutorial"],"articleBody":"I believe many of you have watched or heard of the games between AlphaGo and professional Go player Lee Sedol in 2016. Lee has the highest rank of nine dan and many world championships. No doubt, he is one of the best Go players in the world, but he lost by 1-4 in this series versus AlphaGo. Before this, Go was considered to be an intractable game for computers to master, as its simple rules lay out an exponential number of variations in the board positions, many more than what in Chess. This event surely highlighted 2016 as a big year for AI. Because of AlphaGo, much attention has been attracted to the progress of AI.\nMeanwhile, many companies are spending resources on pushing the edges of AI applications, that indeed have the potential to change or even revolutionize how we are gonna live. Familiar examples include self-driving cars, chatbots, home assistant devices and many others. One of the secret receipts behind the progress we have had in recent years is deep learning.\nWhy Does Deep Learning Work Now? Deep learning models, in simple words, are large and deep artificial neural nets. A neural network (“NN”) can be well presented in a directed acyclic graph: the input layer takes in signal vectors; one or multiple hidden layers process the outputs of the previous layer. The initial concept of a neural network can be traced back to more than half a century ago. But why does it work now? Why do people start talking about them all of a sudden?\nFig. 1: A three-layer artificial neural network. Image source: cs231n.github.io.\nThe reason is surprisingly simple:\nWe have a lot more data. We have much powerful computers. A large and deep neural network has many more layers + many more nodes in each layer, which results in exponentially many more parameters to tune. Without enough data, we cannot learn parameters efficiently. Without powerful computers, learning would be too slow and insufficient.\nHere is an interesting plot presenting the relationship between the data scale and the model performance, proposed by Andrew Ng in his “Nuts and Bolts of Applying Deep Learning” talk. On a small dataset, traditional algorithms (Regression, Random Forests, SVM, GBM, etc.) or statistical learning does a great job, but once the data scale goes up to the sky, the large NN outperforms others. Partially because compared to a traditional ML model, a neural network model has many more parameters and has the capability to learn complicated nonlinear patterns. Thus we expect the model to pick the most helpful features by itself without too much expert-involved manual feature engineering.\nFig. 2: The data scale versus the model performance. Recreated based on: https://youtu.be/F1ka6a13S9I.\nDeep Learning Models Next, let’s go through a few classical deep learning models.\nConvolutional Neural Network Convolutional neural networks, short for “CNN”, is a type of feed-forward artificial neural networks, in which the connectivity pattern between its neurons is inspired by the organization of the visual cortex system. The primary visual cortex (V1) does edge detection out of the raw visual input from the retina. The secondary visual cortex (V2), also called prestriate cortex, receives the edge features from V1 and extracts simple visual properties such as orientation, spatial frequency, and color. The visual area V4 handles more complicated object attributes. All the processed visual features flow into the final logic unit, inferior temporal gyrus (IT), for object recognition. The shortcut between V1 and V4 inspires a special type of CNN with connections between non-adjacent layers: Residual Net (He, et al. 2016) containing “Residual Block” which supports some input of one layer to be passed to the component two layers later.\nFig. 3: Illustration of the human visual cortex system. Image source: Wang \u0026 Raj 2017.\nConvolution is a mathematical term, here referring to an operation between two matrices. The convolutional layer has a fixed small matrix defined, also called kernel or filter. As the kernel is sliding, or convolving, across the matrix representation of the input image, it is computing the element-wise multiplication of the values in the kernel matrix and the original image values. Specially designed kernels can process images for common purposes like blurring, sharpening, edge detection and many others, fast and efficiently.\nFig. 4: The LeNet architecture consists of two sets of convolutional, activation, and pooling layers, followed by a fully-connected layer, activation, another fully-connected layer, and finally a softmax classifier. Image source: http://deeplearning.net/tutorial/lenet.html.\nConvolutional and pooling (or “sub-sampling” in Fig. 4) layers act like the V1, V2 and V4 visual cortex units, responding to feature extraction. The object recognition reasoning happens in the later fully-connected layers which consume the extracted features.\nRecurrent Neural Network A sequence model is usually designed to transform an input sequence into an output sequence that lives in a different domain. Recurrent neural network, short for “RNN”, is suitable for this purpose and has shown tremendous improvement in problems like handwriting recognition, speech recognition, and machine translation (Sutskever et al. 2011, Liwicki et al. 2007).\nA recurrent neural network model is born with the capability to process long sequential data and to tackle tasks with context spreading in time. The model processes one element in the sequence at one time step. After computation, the newly updated unit state is passed down to the next time step to facilitate the computation of the next element. Imagine the case when an RNN model reads all the Wikipedia articles, character by character, and then it can predict the following words given the context.\nFig. 5: A recurrent neural network with one hidden unit (left) and its unrolling version in time (right). The unrolling version illustrates what happens in time: ( s_{t-1} ), ( s_t ), ( s_{t+1} ) are the same unit with different states at different time steps ( t-1 ), ( t ), ( t+1 ). Image source: LeCun, Bengio, and Hinton, 2015; Fig. 5.\nHowever, simple perceptron neurons that linearly combine the current input element and the last unit state may easily lose the long-term dependencies. For example, we start a sentence with “Alice is working at …” and later after a whole paragraph, we want to start the next sentence with “She” or “He” correctly. If the model forgets the character’s name “Alice”, we can never know. To resolve the issue, researchers created a special neuron with a much more complicated internal structure for memorizing long-term context, named “Long-short term memory (LSTM)\" cell. It is smart enough to learn for how long it should memorize the old information, when to forget, when to make use of the new data, and how to combine the old memory with new input. This introduction is so well written that I recommend everyone with interest in LSTM to read it. It has been officially promoted in the Tensorflow documentation ;-)\nFig. 6: The structure of an LSTM cell. Image source: http://colah.github.io/posts/2015-08-Understanding-LSTMs.\nTo demonstrate the power of RNNs, Andrej Karpathy built a character-based language model using RNN with LSTM cells. Without knowing any English vocabulary beforehand, the model could learn the relationship between characters to form words and then the relationship between words to form sentences. It could achieve a decent performance even without a huge set of training data.\nFig. 7: A character-based recurrent neural network model writes like Shakespeare. Image source: http://karpathy.github.io/2015/05/21/rnn-effectiveness.\nRNN: Sequence-to-Sequence Model The sequence-to-sequence model is an extended version of RNN, but its application field is distinguishable enough that I would like to list it in a separated section. Same as RNN, a sequence-to-sequence model operates on sequential data, but particularly it is commonly used to develop chatbots or personal assistants, both generating meaningful response for input questions. A sequence-to-sequence model consists of two RNNs, encoder and decoder. The encoder learns the contextual information from the input words and then hands over the knowledge to the decoder side through a “context vector” (or “thought vector”, as shown in Fig 8.). Finally, the decoder consumes the context vector and generates proper responses.\nFig. 8: A sequence-to-sequence model for generating Gmail auto replies. Image source: Google Blog.\nAutoencoders Different from the previous models, autoencoders are for unsupervised learning. It is designed to learn a low-dimensional representation of a high-dimensional data set, similar to what Principal Components Analysis (PCA) does. The autoencoder model tries to learn an approximation function $f(x) \\approx x$ to reproduce the input data. However, it is restricted by a bottleneck layer in the middle with a very small number of nodes. With limited capacity, the model is forced to form a very efficient encoding of the data, that is essentially the low-dimensional code we learned.\nFig. 9: An autoencoder model has a bottleneck layer with only a few neurons. Image source: Geoffrey Hinton’s Coursera class “Neural Networks for Machine Learning” - Week 15.\nHinton and Salakhutdinov used autoencoders to compress documents on a variety of topics. As shown in Fig 10, when both PCA and autoencoder were applied to reduce the documents onto two dimensions, autoencoder demonstrated a much better outcome. With the help of autoencoder, we can do efficient data compression to speed up the information retrieval including both documents and images.\nFig. 10: The outputs of PCA (left) and autoencoder (right) when both try to compress documents into two numbers. Image source: Hinton \u0026 Salakhutdinov 2006.\nReinforcement (Deep) Learning Since I started my post with AlphaGo, let us dig a bit more on why AlphaGo worked out. Reinforcement learning (“RL”) is one of the secrets behind its success. RL is a subfield of machine learning which allows machines and software agents to automatically determine the optimal behavior within a given context, with a goal to maximize the long-term performance measured by a given metric.\nFig. 11: AlphaGo neural network training pipeline and architecture. Image source: Silver et al. 2016.\nThe AlphaGo system starts with a supervised learning process to train a fast rollout policy and a policy network, relying on the manually curated training dataset of professional players’ games. It learns what is the best strategy given the current position on the game board. Then it applies reinforcement learning by setting up self-play games. The RL policy network gets improved when it wins more and more games against previous versions of the policy network. In the self-play stage, AlphaGo becomes stronger and stronger by playing against itself without requiring additional external training data.\nGenerative Adversarial Network Generative adversarial network, short for “GAN”, is a type of deep generative models. GAN is able to create new examples after learning through the real data. It is consist of two models competing against each other in a zero-sum game framework. The famous deep learning researcher Yann LeCun gave it a super high praise: Generative Adversarial Network is the most interesting idea in the last ten years in machine learning. (See the Quora question: “What are some recent and potentially upcoming breakthroughs in deep learning?\")\nFig. 12: The architecture of a generative adversarial network. Image source: http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html.\nIn the original GAN paper, GAN was proposed to generate meaningful images after learning from real photos. It comprises two independent models: the Generator and the Discriminator. The generator produces fake images and sends the output to the discriminator model. The discriminator works like a judge, as it is optimized for identifying the real photos from the fake ones. The generator model is trying hard to cheat the discriminator while the judge is trying hard not to be cheated. This interesting zero-sum game between these two models motivates both to develop their designed skills and improve their functionalities. Eventually, we take the generator model for producing new images.\nToolkits and Libraries After learning all these models, you may start wondering how you can implement the models and use them for real. Fortunately, we have many open source toolkits and libraries for building deep learning models. Tensorflow is fairly new but has attracted a lot of popularity. It turns out, TensorFlow was the most forked Github project of 2015. All that happened in a period of 2 months after its release in Nov 2015.\nHow to Learn? If you are very new to the field and willing to devote some time to studying deep learning in a more systematic way, I would recommend you to start with the book Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville. The Coursera course “Neural Networks for Machine Learning” by Geoffrey Hinton (Godfather of deep learning!). The content for the course was prepared around 2006, pretty old, but it helps you build up a solid foundation for understanding deep learning models and expedite further exploration.\nMeanwhile, maintain your curiosity and passion. The field is making progress every day. Even classical or widely adopted deep learning models may just have been proposed 1-2 years ago. Reading academic papers can help you learn stuff in depth and keep up with the cutting-edge findings.\nUseful resources Google Scholar: http://scholar.google.com/ arXiv cs section: https://arxiv.org/list/cs/recent Unsupervised Feature Learning and Deep Learning Tutorial Tensorflow Tutorials Data Science Weekly KDnuggets Tons of blog posts and online tutorials Related Cousera courses awesome-deep-learning-papers Blog posts mentioned Explained Visually: Image Kernels Understanding LSTM Networks The Unreasonable Effectiveness of Recurrent Neural Networks Computer, respond to this email. Interesting blogs worthy of checking www.wildml.com colah.github.io karpathy.github.io blog.openai.com Papers mentioned [1] He, Kaiming, et al. “Deep residual learning for image recognition.\" Proc. IEEE Conf. on computer vision and pattern recognition. 2016.\n[2] Wang, Haohan, Bhiksha Raj, and Eric P. Xing. “On the Origin of Deep Learning.\" arXiv preprint arXiv:1702.07800, 2017.\n[3] Sutskever, Ilya, James Martens, and Geoffrey E. Hinton. “Generating text with recurrent neural networks.\" Proc. of the 28th Intl. Conf. on Machine Learning (ICML). 2011.\n[4] Liwicki, Marcus, et al. “A novel approach to on-line handwriting recognition based on bidirectional long short-term memory networks.\" Proc. of 9th Intl. Conf. on Document Analysis and Recognition. 2007.\n[5] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “Deep learning.\" Nature 521.7553 (2015): 436-444.\n[6] Hochreiter, Sepp, and Jurgen Schmidhuber. “Long short-term memory.\" Neural computation 9.8 (1997): 1735-1780.\n[7] Cho, Kyunghyun. et al. “Learning phrase representations using RNN encoder-decoder for statistical machine translation.\" Proc. Conference on Empirical Methods in Natural Language Processing 1724–1734 (2014).\n[8] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. “Reducing the dimensionality of data with neural networks.\" science 313.5786 (2006): 504-507.\n[9] Silver, David, et al. “Mastering the game of Go with deep neural networks and tree search.\" Nature 529.7587 (2016): 484-489.\n[10] Goodfellow, Ian, et al. “Generative adversarial nets.\" NIPS, 2014.\n","wordCount":"2412","inLanguage":"en","datePublished":"2017-06-21T12:06:59+08:00","dateModified":"2017-06-21T12:06:59+08:00","author":{"@type":"Person","name":"Jarvis Ma"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/post/2017-06-21-overview/an-overview-of-deep-learning-for-curious-people/"},"publisher":{"@type":"Organization","name":"Jarvis' Log","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Jarvis' Log (Alt + H)"><img src=http://localhost:1313/favicon.ico alt aria-label=logo height=15>Jarvis' Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/archives/ title=Archives><span>Archives</span></a></li><li><a href=http://localhost:1313/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://example.org title=example.org><span>example.org</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">An Overview of Deep Learning for Curious People</h1><div class=post-meta><span title='2017-06-21 12:06:59 +0800 CST'>Jun 21, 2017</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;2412 words&nbsp;·&nbsp;Jarvis Ma&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/post/2017-06-21-overview/an-overview-of-deep-learning-for-curious-people.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#why-does-deep-learning-work-now>Why Does Deep Learning Work Now?</a></li><li><a href=#deep-learning-models>Deep Learning Models</a><ul><li><a href=#convolutional-neural-network>Convolutional Neural Network</a></li><li><a href=#recurrent-neural-network>Recurrent Neural Network</a></li><li><a href=#rnn-sequence-to-sequence-model>RNN: Sequence-to-Sequence Model</a></li><li><a href=#autoencoders>Autoencoders</a></li></ul></li><li><a href=#reinforcement-deep-learning>Reinforcement (Deep) Learning</a><ul><li><a href=#generative-adversarial-network>Generative Adversarial Network</a></li></ul></li><li><a href=#toolkits-and-libraries>Toolkits and Libraries</a></li><li><a href=#how-to-learn>How to Learn?</a><ul><li><a href=#useful-resources>Useful resources</a></li><li><a href=#blog-posts-mentioned>Blog posts mentioned</a></li><li><a href=#interesting-blogs-worthy-of-checking>Interesting blogs worthy of checking</a></li><li><a href=#papers-mentioned>Papers mentioned</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p>I believe many of you have watched or heard of the <a href=https://youtu.be/vFr3K2DORc8>games</a> between AlphaGo and professional Go player <a href=https://en.wikipedia.org/wiki/Lee_Sedol>Lee Sedol</a> in 2016. Lee has the highest rank of nine dan and many world championships. No doubt, he is one of the best Go players in the world, but he <a href=https://www.scientificamerican.com/article/how-the-computer-beat-the-go-master/>lost by 1-4</a> in this series versus AlphaGo. Before this, Go was considered to be an intractable game for computers to master, as its simple rules lay out an exponential number of variations in the board positions, many more than what in Chess. This event surely highlighted 2016 as a big year for AI. Because of AlphaGo, much attention has been attracted to the progress of AI.</p><p>Meanwhile, many companies are spending resources on pushing the edges of AI applications, that indeed have the potential to change or even revolutionize how we are gonna live. Familiar examples include self-driving cars, chatbots, home assistant devices and many others. One of the secret receipts behind the progress we have had in recent years is deep learning.</p><h2 id=why-does-deep-learning-work-now>Why Does Deep Learning Work Now?<a hidden class=anchor aria-hidden=true href=#why-does-deep-learning-work-now>#</a></h2><p>Deep learning models, in simple words, are large and deep artificial neural nets. A neural network (“NN”) can be well presented in a <a href=https://en.wikipedia.org/wiki/Directed_acyclic_graph>directed acyclic graph</a>: the input layer takes in signal vectors; one or multiple hidden layers process the outputs of the previous layer. The initial concept of a neural network can be traced back to more than <a href=https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/history1.html>half a century ago</a>. But why does it work now? Why do people start talking about them all of a sudden?</p><p><img loading=lazy src=/post/2017-06-21-overview/ANN.png alt="A Three-Layer Artificial Neural Network"></p><p><em>Fig. 1: A three-layer artificial neural network. Image source: <a href=http://cs231n.github.io/convolutional-networks/#conv>cs231n.github.io</a>.</em></p><p>The reason is surprisingly simple:</p><ul><li>We have a lot <strong>more data</strong>.</li><li>We have <strong>much powerful computers</strong>.</li></ul><p>A large and deep neural network has many more layers + many more nodes in each layer, which results in exponentially many more parameters to tune. Without enough data, we cannot learn parameters efficiently. Without powerful computers, learning would be too slow and insufficient.</p><p>Here is an interesting plot presenting the relationship between the data scale and the model performance, proposed by Andrew Ng in his “<a href=https://youtu.be/F1ka6a13S9I>Nuts and Bolts of Applying Deep Learning</a>” talk. On a small dataset, traditional algorithms (Regression, Random Forests, SVM, GBM, etc.) or statistical learning does a great job, but once the data scale goes up to the sky, the large NN outperforms others. Partially because compared to a traditional ML model, a neural network model has many more parameters and has the capability to learn complicated nonlinear patterns. Thus we expect the model to pick the most helpful features by itself without too much expert-involved manual feature engineering.</p><p><img loading=lazy src=/post/2017-06-21-overview/data_size_vs_model_performance.png alt="The Data Scale Versus the Model Performance"></p><p><em>Fig. 2: The data scale versus the model performance. Recreated based on: <a href=https://youtu.be/F1ka6a13S9I>https://youtu.be/F1ka6a13S9I</a>.</em></p><h2 id=deep-learning-models>Deep Learning Models<a hidden class=anchor aria-hidden=true href=#deep-learning-models>#</a></h2><p>Next, let’s go through a few classical deep learning models.</p><h3 id=convolutional-neural-network>Convolutional Neural Network<a hidden class=anchor aria-hidden=true href=#convolutional-neural-network>#</a></h3><p>Convolutional neural networks, short for “CNN”, is a type of feed-forward artificial neural networks, in which the connectivity pattern between its neurons is inspired by the organization of the visual cortex system. The primary visual cortex (V1) does edge detection out of the raw visual input from the retina. The secondary visual cortex (V2), also called prestriate cortex, receives the edge features from V1 and extracts simple visual properties such as orientation, spatial frequency, and color. The visual area V4 handles more complicated object attributes. All the processed visual features flow into the final logic unit, inferior temporal gyrus (IT), for object recognition. The shortcut between V1 and V4 inspires a special type of CNN with connections between non-adjacent layers: Residual Net (<a href=http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf>He, et al. 2016</a>) containing “Residual Block” which supports some input of one layer to be passed to the component two layers later.</p><p><img loading=lazy src=/post/2017-06-21-overview/visual_cortex_system.png alt="Illustration of the Human Visual Cortex System"></p><p><em>Fig. 3: Illustration of the human visual cortex system. Image source: <a href=https://arxiv.org/abs/1702.07800>Wang & Raj 2017</a>.</em></p><p>Convolution is a mathematical term, here referring to an operation between two matrices. The convolutional layer has a fixed small matrix defined, also called kernel or filter. As the kernel is sliding, or convolving, across the matrix representation of the input image, it is computing the element-wise multiplication of the values in the kernel matrix and the original image values. <a href=http://setosa.io/ev/image-kernels/>Specially designed kernels</a> can process images for common purposes like blurring, sharpening, edge detection and many others, fast and efficiently.</p><p><img loading=lazy src=/post/2017-06-21-overview/lenet.png alt="The LeNet Architecture"></p><p><em>Fig. 4: The LeNet architecture consists of two sets of convolutional, activation, and pooling layers, followed by a fully-connected layer, activation, another fully-connected layer, and finally a softmax classifier. Image source: <a href=http://deeplearning.net/tutorial/lenet.html>http://deeplearning.net/tutorial/lenet.html</a>.</em></p><p><a href=http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/>Convolutional</a> and <a href=http://ufldl.stanford.edu/tutorial/supervised/Pooling/>pooling</a> (or “sub-sampling” in Fig. 4) layers act like the V1, V2 and V4 visual cortex units, responding to feature extraction. The object recognition reasoning happens in the later fully-connected layers which consume the extracted features.</p><h3 id=recurrent-neural-network>Recurrent Neural Network<a hidden class=anchor aria-hidden=true href=#recurrent-neural-network>#</a></h3><p>A sequence model is usually designed to transform an input sequence into an output sequence that lives in a different domain. Recurrent neural network, short for “RNN”, is suitable for this purpose and has shown tremendous improvement in problems like handwriting recognition, speech recognition, and machine translation (<a href=http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf>Sutskever et al. 2011</a>, <a href=http://www6.in.tum.de/Main/Publications/Liwicki2007a.pdf>Liwicki et al. 2007</a>).</p><p>A recurrent neural network model is born with the capability to process long sequential data and to tackle tasks with context spreading in time. The model processes one element in the sequence at one time step. After computation, the newly updated unit state is passed down to the next time step to facilitate the computation of the next element. Imagine the case when an RNN model reads all the Wikipedia articles, character by character, and then it can predict the following words given the context.</p><p><img loading=lazy src=/post/2017-06-21-overview/RNN.png alt="A Recurrent Neural Network"></p><p><em>Fig. 5: A recurrent neural network with one hidden unit (left) and its unrolling version in time (right). The unrolling version illustrates what happens in time: ( s_{t-1} ), ( s_t ), ( s_{t+1} ) are the same unit with different states at different time steps ( t-1 ), ( t ), ( t+1 ). Image source: <a href=http://pages.cs.wisc.edu/~dyer/cs540/handouts/deep-learning-nature2015.pdf>LeCun, Bengio, and Hinton, 2015</a>; <a href=https://www.nature.com/nature/journal/v521/n7553/fig_tab/nature14539_F5.html>Fig. 5</a>.</em></p><p>However, simple perceptron neurons that linearly combine the current input element and the last unit state may easily lose the long-term dependencies. For example, we start a sentence with “Alice is working at …” and later after a whole paragraph, we want to start the next sentence with “She” or “He” correctly. If the model forgets the character’s name “Alice”, we can never know. To resolve the issue, researchers created a special neuron with a much more complicated internal structure for memorizing long-term context, named “<a href=http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf>Long-short term memory (LSTM)</a>" cell. It is smart enough to learn for how long it should memorize the old information, when to forget, when to make use of the new data, and how to combine the old memory with new input. This <a href=http://colah.github.io/posts/2015-08-Understanding-LSTMs/>introduction</a> is so well written that I recommend everyone with interest in LSTM to read it. It has been officially promoted in the <a href=https://www.tensorflow.org/tutorials/recurrent>Tensorflow documentation</a> ;-)</p><p><img loading=lazy src=/post/2017-06-21-overview/LSTM.png alt="The Structure of an LSTM Cell"></p><p><em>Fig. 6: The structure of an LSTM cell. Image source: <a href=http://colah.github.io/posts/2015-08-Understanding-LSTMs>http://colah.github.io/posts/2015-08-Understanding-LSTMs</a>.</em></p><p>To demonstrate the power of RNNs, <a href=http://karpathy.github.io/2015/05/21/rnn-effectiveness/>Andrej Karpathy</a> built a character-based language model using RNN with LSTM cells. Without knowing any English vocabulary beforehand, the model could learn the relationship between characters to form words and then the relationship between words to form sentences. It could achieve a decent performance even without a huge set of training data.</p><p><img loading=lazy src=/post/2017-06-21-overview/rnn_shakespeare.png alt="A Character-Based Recurrent Neural Network Model Writes Like Shakespeare"></p><p><em>Fig. 7: A character-based recurrent neural network model writes like Shakespeare. Image source: <a href=http://karpathy.github.io/2015/05/21/rnn-effectiveness>http://karpathy.github.io/2015/05/21/rnn-effectiveness</a>.</em></p><h3 id=rnn-sequence-to-sequence-model>RNN: Sequence-to-Sequence Model<a hidden class=anchor aria-hidden=true href=#rnn-sequence-to-sequence-model>#</a></h3><p>The <a href=https://arxiv.org/pdf/1406.1078.pdf>sequence-to-sequence model</a> is an extended version of RNN, but its application field is distinguishable enough that I would like to list it in a separated section. Same as RNN, a sequence-to-sequence model operates on sequential data, but particularly it is commonly used to develop chatbots or personal assistants, both generating meaningful response for input questions. A sequence-to-sequence model consists of two RNNs, encoder and decoder. The encoder learns the contextual information from the input words and then hands over the knowledge to the decoder side through a “<strong>context vector</strong>” (or “thought vector”, as shown in Fig 8.). Finally, the decoder consumes the context vector and generates proper responses.</p><p><img loading=lazy src=/post/2017-06-21-overview/seq2seq_gmail.png alt="A Sequence-to-Sequence Model for Generating Gmail Auto Replies"></p><p><em>Fig. 8: A sequence-to-sequence model for generating Gmail auto replies. Image source: <a href=https://research.googleblog.com/2015/11/computer-respond-to-this-email.html>Google Blog</a>.</em></p><h3 id=autoencoders>Autoencoders<a hidden class=anchor aria-hidden=true href=#autoencoders>#</a></h3><p>Different from the previous models, autoencoders are for unsupervised learning. It is designed to learn a <strong>low-dimensional</strong> representation of a <strong>high-dimensional</strong> data set, similar to what <a href=https://en.wikipedia.org/wiki/Principal_component_analysis>Principal Components Analysis (PCA)</a> does. The autoencoder model tries to learn an approximation function $f(x) \approx x$ to reproduce the input data. However, it is restricted by a bottleneck layer in the middle with a very small number of nodes. With limited capacity, the model is forced to form a very efficient encoding of the data, that is essentially the low-dimensional code we learned.</p><p><img loading=lazy src=/post/2017-06-21-overview/autoencoder.png alt="An Autoencoder Model with a Bottleneck Layer"></p><p><em>Fig. 9: An autoencoder model has a bottleneck layer with only a few neurons. Image source: Geoffrey Hinton’s Coursera class <a href=https://www.coursera.org/learn/neural-networks>&ldquo;Neural Networks for Machine Learning&rdquo;</a> - <a href=https://www.coursera.org/learn/neural-networks/home/week/15>Week 15</a>.</em></p><p><a href=https://pdfs.semanticscholar.org/7d76/b71b700846901ac4ac119403aa737a285e36.pdf>Hinton and Salakhutdinov</a> used autoencoders to compress documents on a variety of topics. As shown in Fig 10, when both PCA and autoencoder were applied to reduce the documents onto two dimensions, autoencoder demonstrated a much better outcome. With the help of autoencoder, we can do efficient data compression to speed up the information retrieval including both documents and images.</p><p><img loading=lazy src=/post/2017-06-21-overview/autoencoder_experiment.png alt="PCA vs Autoencoder Outputs"></p><p><em>Fig. 10: The outputs of PCA (left) and autoencoder (right) when both try to compress documents into two numbers. Image source: <a href=https://www.cs.toronto.edu/~hinton/science.pdf>Hinton & Salakhutdinov 2006</a>.</em></p><h2 id=reinforcement-deep-learning>Reinforcement (Deep) Learning<a hidden class=anchor aria-hidden=true href=#reinforcement-deep-learning>#</a></h2><p>Since I started my post with AlphaGo, let us dig a bit more on why AlphaGo worked out. <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>Reinforcement learning (“RL”)</a> is one of the secrets behind its success. RL is a subfield of machine learning which allows machines and software agents to automatically determine the optimal behavior within a given context, with a goal to maximize the long-term performance measured by a given metric.</p><p><img loading=lazy src=/post/2017-06-21-overview/alphago_paper.png alt="AlphaGo Neural Network Training Pipeline and Architecture"></p><p><em>Fig. 11: AlphaGo neural network training pipeline and architecture. Image source: <a href=https://www.nature.com/articles/nature16961>Silver et al. 2016</a>.</em></p><p>The AlphaGo system starts with a supervised learning process to train a fast rollout policy and a policy network, relying on the manually curated training dataset of professional players&rsquo; games. It learns what is the best strategy given the current position on the game board. Then it applies reinforcement learning by setting up self-play games. The RL policy network gets improved when it wins more and more games against previous versions of the policy network. In the self-play stage, AlphaGo becomes stronger and stronger by playing against itself without requiring additional external training data.</p><h3 id=generative-adversarial-network>Generative Adversarial Network<a hidden class=anchor aria-hidden=true href=#generative-adversarial-network>#</a></h3><p><a href=https://arxiv.org/pdf/1406.2661.pdf>Generative adversarial network</a>, short for “GAN”, is a type of deep generative models. GAN is able to create new examples after learning through the real data. It is consist of two models competing against each other in a zero-sum game framework. The famous deep learning researcher <a href=http://yann.lecun.com/>Yann LeCun</a> gave it a super high praise: Generative Adversarial Network is the most interesting idea in the last ten years in machine learning. (See the Quora question: <a href=https://www.quora.com/What-are-some-recent-and-potentially-upcoming-breakthroughs-in-deep-learning>“What are some recent and potentially upcoming breakthroughs in deep learning?"</a>)</p><p><img loading=lazy src=/post/2017-06-21-overview/GAN.png alt="The Architecture of a Generative Adversarial Network"></p><p><em>Fig. 12: The architecture of a generative adversarial network. Image source: <a href=http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html>http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html</a>.</em></p><p>In the <a href=https://arxiv.org/pdf/1406.2661.pdf>original GAN paper</a>, GAN was proposed to generate meaningful images after learning from real photos. It comprises two independent models: the <strong>Generator</strong> and the <strong>Discriminator</strong>. The generator produces fake images and sends the output to the discriminator model. The discriminator works like a judge, as it is optimized for identifying the real photos from the fake ones. The generator model is trying hard to cheat the discriminator while the judge is trying hard not to be cheated. This interesting zero-sum game between these two models motivates both to develop their designed skills and improve their functionalities. Eventually, we take the generator model for producing new images.</p><h2 id=toolkits-and-libraries>Toolkits and Libraries<a hidden class=anchor aria-hidden=true href=#toolkits-and-libraries>#</a></h2><p>After learning all these models, you may start wondering how you can implement the models and use them for real. Fortunately, we have many open source toolkits and libraries for building deep learning models. <a href=https://www.tensorflow.org/>Tensorflow</a> is fairly new but has attracted a lot of popularity. It turns out, TensorFlow was <a href=http://deliprao.com/archives/168>the most forked Github project of 2015</a>. All that happened in a period of 2 months after its release in Nov 2015.</p><p><img loading=lazy src=/post/2017-06-21-overview/deep_learning_toolkits.png alt="Deep Learning Toolkits"></p><h2 id=how-to-learn>How to Learn?<a hidden class=anchor aria-hidden=true href=#how-to-learn>#</a></h2><p>If you are very new to the field and willing to devote some time to studying deep learning in a more systematic way, I would recommend you to start with the book <a href="https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1499413305&amp;sr=1-1&amp;keywords=deep+learning">Deep Learning</a> by Ian Goodfellow, Yoshua Bengio, and Aaron Courville. The Coursera course <a href=https://www.coursera.org/learn/neural-networks>“Neural Networks for Machine Learning”</a> by Geoffrey Hinton (<a href=https://youtu.be/uAu3jQWaN6E>Godfather of deep learning!</a>). The content for the course was prepared around 2006, pretty old, but it helps you build up a solid foundation for understanding deep learning models and expedite further exploration.</p><p>Meanwhile, maintain your curiosity and passion. The field is making progress every day. Even classical or widely adopted deep learning models may just have been proposed 1-2 years ago. Reading academic papers can help you learn stuff in depth and keep up with the cutting-edge findings.</p><h3 id=useful-resources>Useful resources<a hidden class=anchor aria-hidden=true href=#useful-resources>#</a></h3><ul><li>Google Scholar: <a href=http://scholar.google.com/>http://scholar.google.com/</a></li><li>arXiv cs section: <a href=https://arxiv.org/list/cs/recent>https://arxiv.org/list/cs/recent</a></li><li><a href=http://ufldl.stanford.edu/tutorial/>Unsupervised Feature Learning and Deep Learning Tutorial</a></li><li><a href=https://www.tensorflow.org/tutorials/>Tensorflow Tutorials</a></li><li>Data Science Weekly</li><li><a href=http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html>KDnuggets</a></li><li>Tons of blog posts and online tutorials</li><li>Related <a href=http://coursera.com/>Cousera</a> courses</li><li><a href=https://github.com/terryum/awesome-deep-learning-papers>awesome-deep-learning-papers</a></li></ul><h3 id=blog-posts-mentioned>Blog posts mentioned<a hidden class=anchor aria-hidden=true href=#blog-posts-mentioned>#</a></h3><ul><li><a href=http://setosa.io/ev/image-kernels>Explained Visually: Image Kernels</a></li><li><a href=http://colah.github.io/posts/2015-08-Understanding-LSTMs/>Understanding LSTM Networks</a></li><li><a href=http://karpathy.github.io/2015/05/21/rnn-effectiveness/>The Unreasonable Effectiveness of Recurrent Neural Networks</a></li><li><a href=https://research.googleblog.com/2015/11/computer-respond-to-this-email.html>Computer, respond to this email.</a></li></ul><h3 id=interesting-blogs-worthy-of-checking>Interesting blogs worthy of checking<a hidden class=anchor aria-hidden=true href=#interesting-blogs-worthy-of-checking>#</a></h3><ul><li><a href=http://www.wildml.com/>www.wildml.com</a></li><li><a href=http://colah.github.io/>colah.github.io</a></li><li><a href=http://karpathy.github.io/>karpathy.github.io</a></li><li><a href=https://blog.openai.com/>blog.openai.com</a></li></ul><h3 id=papers-mentioned>Papers mentioned<a hidden class=anchor aria-hidden=true href=#papers-mentioned>#</a></h3><p>[1] He, Kaiming, et al. <a href=http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf>“Deep residual learning for image recognition."</a> Proc. IEEE Conf. on computer vision and pattern recognition. 2016.</p><p>[2] Wang, Haohan, Bhiksha Raj, and Eric P. Xing. <a href=https://arxiv.org/pdf/1702.07800.pdf>“On the Origin of Deep Learning."</a> arXiv preprint arXiv:1702.07800, 2017.</p><p>[3] Sutskever, Ilya, James Martens, and Geoffrey E. Hinton. <a href=http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf>“Generating text with recurrent neural networks."</a> Proc. of the 28th Intl. Conf. on Machine Learning (ICML). 2011.</p><p>[4] Liwicki, Marcus, et al. <a href=http://www6.in.tum.de/Main/Publications/Liwicki2007a.pdf>“A novel approach to on-line handwriting recognition based on bidirectional long short-term memory networks."</a> Proc. of 9th Intl. Conf. on Document Analysis and Recognition. 2007.</p><p>[5] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. <a href=http://pages.cs.wisc.edu/~dyer/cs540/handouts/deep-learning-nature2015.pdf>“Deep learning."</a> Nature 521.7553 (2015): 436-444.</p><p>[6] Hochreiter, Sepp, and Jurgen Schmidhuber. <a href=http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf>“Long short-term memory."</a> Neural computation 9.8 (1997): 1735-1780.</p><p>[7] Cho, Kyunghyun. et al. <a href=https://arxiv.org/pdf/1406.1078.pdf>“Learning phrase representations using RNN encoder-decoder for statistical machine translation."</a> Proc. Conference on Empirical Methods in Natural Language Processing 1724–1734 (2014).</p><p>[8] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. <a href=https://pdfs.semanticscholar.org/7d76/b71b700846901ac4ac119403aa737a285e36.pdf>“Reducing the dimensionality of data with neural networks." </a>science 313.5786 (2006): 504-507.</p><p>[9] Silver, David, et al. <a href=http://web.iitd.ac.in/~sumeet/Silver16.pdf>“Mastering the game of Go with deep neural networks and tree search."</a> Nature 529.7587 (2016): 484-489.</p><p>[10] Goodfellow, Ian, et al. <a href=https://arxiv.org/pdf/1406.2661.pdf>“Generative adversarial nets."</a> NIPS, 2014.</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/foundation/>Foundation</a></li><li><a href=http://localhost:1313/tags/tutorial/>Tutorial</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/post/2017-07-08-stock-rnn-part-1/predict-stock-prices-using-rnn-part1/><span class=title>« Prev</span><br><span>Predict Stock Prices Using Rnn Part 1</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Deep Learning for Curious People on x" href="https://x.com/intent/tweet/?text=An%20Overview%20of%20Deep%20Learning%20for%20Curious%20People&amp;url=http%3a%2f%2flocalhost%3a1313%2fpost%2f2017-06-21-overview%2fan-overview-of-deep-learning-for-curious-people%2f&amp;hashtags=foundation%2ctutorial"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Deep Learning for Curious People on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fpost%2f2017-06-21-overview%2fan-overview-of-deep-learning-for-curious-people%2f&amp;title=An%20Overview%20of%20Deep%20Learning%20for%20Curious%20People&amp;summary=An%20Overview%20of%20Deep%20Learning%20for%20Curious%20People&amp;source=http%3a%2f%2flocalhost%3a1313%2fpost%2f2017-06-21-overview%2fan-overview-of-deep-learning-for-curious-people%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Deep Learning for Curious People on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fpost%2f2017-06-21-overview%2fan-overview-of-deep-learning-for-curious-people%2f&title=An%20Overview%20of%20Deep%20Learning%20for%20Curious%20People"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Deep Learning for Curious People on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fpost%2f2017-06-21-overview%2fan-overview-of-deep-learning-for-curious-people%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Deep Learning for Curious People on whatsapp" href="https://api.whatsapp.com/send?text=An%20Overview%20of%20Deep%20Learning%20for%20Curious%20People%20-%20http%3a%2f%2flocalhost%3a1313%2fpost%2f2017-06-21-overview%2fan-overview-of-deep-learning-for-curious-people%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Deep Learning for Curious People on telegram" href="https://telegram.me/share/url?text=An%20Overview%20of%20Deep%20Learning%20for%20Curious%20People&amp;url=http%3a%2f%2flocalhost%3a1313%2fpost%2f2017-06-21-overview%2fan-overview-of-deep-learning-for-curious-people%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Deep Learning for Curious People on ycombinator" href="https://news.ycombinator.com/submitlink?t=An%20Overview%20of%20Deep%20Learning%20for%20Curious%20People&u=http%3a%2f%2flocalhost%3a1313%2fpost%2f2017-06-21-overview%2fan-overview-of-deep-learning-for-curious-people%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Jarvis' Log</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>